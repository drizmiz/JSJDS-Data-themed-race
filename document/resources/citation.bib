
@article{doi:10.1080/01621459.2021.1920957,
author = {Victor Chernozhukov and Kaspar Wüthrich and Yinchu Zhu},
title = {An Exact and Robust Conformal Inference Method for Counterfactual and Synthetic Controls},
journal = {Journal of the American Statistical Association},
volume = {0},
number = {ja},
pages = {1-44},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2021.1920957},

URL = { 
        https://doi.org/10.1080/01621459.2021.1920957
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2021.1920957
    
}

}

@Manual{citation_ggdag,
    title = {ggdag: Analyze and Create Elegant Directed Acyclic Graphs},
    author = {Malcolm Barrett},
    year = {2021},
    note = {R package version 0.2.3},
    url = {https://CRAN.R-project.org/package=ggdag},
  }

@book{Wickham2017R,
  abstract = {Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible.

Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. You'll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what you've learned along the way.

You'll learn how to:

    Wrangle—transform your datasets into a form convenient for analysis
    Program—learn powerful R tools for solving data problems with greater clarity and ease
    Explore—examine your data, generate hypotheses, and quickly test them
    Model—provide a low-dimensional summary that captures true "signals" in your dataset
    Communicate—learn R Markdown for integrating prose, code, and results},
  added-at = {2018-06-18T21:23:34.000+0200},
  author = {Wickham, Hadley and Grolemund, Garrett},
  biburl = {https://www.bibsonomy.org/bibtex/22e6e5a8bda4b8020e3b4e90c5accf9a8/pbett},
  citeulike-article-id = {14263839},
  citeulike-linkout-0 = {http://r4ds.had.co.nz/},
  citeulike-linkout-1 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/1491910399},
  citeulike-linkout-10 = {http://www.librarything.com/isbn/1491910399},
  citeulike-linkout-11 = {http://www.worldcat.org/oclc/979415716},
  citeulike-linkout-2 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/1491910399},
  citeulike-linkout-3 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/1491910399},
  citeulike-linkout-4 = {http://www.amazon.jp/exec/obidos/ASIN/1491910399},
  citeulike-linkout-5 = {http://www.amazon.co.uk/exec/obidos/ASIN/1491910399/citeulike00-21},
  citeulike-linkout-6 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1491910399},
  citeulike-linkout-7 = {http://www.worldcat.org/isbn/1491910399},
  citeulike-linkout-8 = {http://books.google.com/books?vid=ISBN1491910399},
  citeulike-linkout-9 = {http://www.amazon.com/gp/search?keywords=1491910399&index=books&linkCode=qs},
  comment = {Available (section-by-section) online from http://r4ds.had.co.nz/},
  day = 05,
  edition = 1,
  howpublished = {Paperback},
  interhash = {660059a5b6b582a913488afb63e66907},
  intrahash = {2e6e5a8bda4b8020e3b4e90c5accf9a8},
  isbn = {1491910399},
  keywords = {visualisation textbook computing rpackage},
  month = jan,
  posted-at = {2017-04-03 14:44:51},
  priority = {2},
  publisher = {O'Reilly Media},
  timestamp = {2018-06-22T18:36:55.000+0200},
  title = {R for Data Science: Import, Tidy, Transform, Visualize, and Model Data},
  url = {http://r4ds.had.co.nz/},
  year = 2017
}

@Article{citation_mice,
    title = {{mice}: Multivariate Imputation by Chained Equations in R},
    author = {Stef {van Buuren} and Karin Groothuis-Oudshoorn},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {45},
    number = {3},
    pages = {1-67},
    url = {https://www.jstatsoft.org/v45/i03/},
  }

@Article{citation_VIM,
    title = {Imputation with the {R} Package {VIM}},
    author = {Alexander Kowarik and Matthias Templ},
    journal = {Journal of Statistical Software},
    year = {2016},
    volume = {74},
    number = {7},
    pages = {1--16},
    doi = {10.18637/jss.v074.i07},
  }

@Article{tidy-data,
  author = {Hadley Wickham},
  issue = {10},
  journal = {The Journal of Statistical Software},
  selected = {TRUE},
  title = {Tidy data},
  url = {http://www.jstatsoft.org/v59/i10/},
  volume = {59},
  year = {2014},
  bdsk-url-1 = {http://www.jstatsoft.org/v59/i10/},
}


@book{pearl, 
  place = {Chichester}, 
  title = {Causal inference in statistics: a primer}, 
  publisher = {Wiley},
  author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
  year = {2019}
}


@article{LI2018136,
title = {ECharts: A declarative framework for rapid construction of web-based visualization},
journal = {Visual Informatics},
volume = {2},
number = {2},
pages = {136-146},
year = {2018},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2018.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X18300068},
author = {Deqing Li and Honghui Mei and Yi Shen and Shuang Su and Wenli Zhang and Junting Wang and Ming Zu and Wei Chen},
keywords = {Information visualization, Web-based visualization},
abstract = {While there have been a dozen of authoring systems and programming toolkits for visual design and development, users who do not have programming skills, such as data analysts or interface designers, still may feel cumbersome to efficiently implement a web-based visualization. In this paper, we present ECharts, an open-sourced, web-based, cross-platform framework that supports the rapid construction of interactive visualization. The motivation is driven by three goals: easy-to-use, rich built-in interactions, and high performance. The kernel of ECharts is a suite of declarative visual design language that customizes built-in chart types. The underlying streaming architecture, together with a high-performance graphics renderer based on HTML5 canvas, enables the high expandability and performance of ECharts. We report the design, implementation, and applications of ECharts with a diverse variety of examples. We compare the utility and performance of ECharts with C3.js, HighCharts, and Chart.js. Results of the experiments demonstrate the efficiency and scalability of our framework. Since the first release in June 2013, ECharts has iterated 63 versions, and attracted over 22,000 star counts and over 1700 related projects in the GitHub. ECharts is regarded as a leading visualization development tool in the world, and ranks the third in the GitHub visualization tab.}
}

@book{wickham_2019,
 place={Boca Raton}, 
 title={Advanced R}, 
 publisher={CRC Press},
  author={Wickham, Hadley},
   year={2019}
} 

@techreport{NBERw22791,
 title = "Balancing, Regression, Difference-In-Differences and Synthetic Control Methods: A Synthesis",
 author = "Doudchenko, Nikolay and Imbens, Guido W",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "22791",
 year = "2016",
 month = "October",
 doi = {10.3386/w22791},
 URL = "http://www.nber.org/papers/w22791",
 abstract = {In a seminal paper Abadie et al (2010) develop the synthetic control procedure for estimating the effect of a treatment, in the presence of a single treated unit and a number of control units, with pre-treatment outcomes observed for all units. The method constructs a set of weights such that covariates and  pre-treatment outcomes of the treated unit are approximately matched by a weighted average of control units. The weights are  restricted to be nonnegative and sum to one, which allows the procedure to obtain the weights even when the number of lagged outcomes is modest relative to the number of control units, a setting that is not uncommon in applications.  In the current paper we propose a more general class of synthetic control estimators that allows researchers to relax some of the restrictions in the ADH method. We allow the weights to be negative, do not necessarily restrict the sum of the weights, and allow for a permanent additive difference between the treated unit and the controls, similar to difference-in-difference procedures. The weights directly minimize the distance between the lagged outcomes for the treated and the control units, using regularization methods to deal with a potentially large number of possible control units.},
}

@article{sc_method,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/3132164},
 abstract = {This article investigates the economic effects of conflict, using the terrorist conflict in the Basque Country as a case study. We find that, after the outbreak of terrorism in the late 1960's, per capita GDP in the Basque Country declined about 10 percentage points relative to a synthetic control region without terrorism. In addition, we use the 1998-1999 truce as a natural experiment. We find that stocks of firms with a significant part of their business in the Basque Country showed a positive relative performance when truce became credible, and a negative relative performance at the end of the cease-fire.},
 author = {Alberto Abadie and Javier Gardeazabal},
 journal = {The American Economic Review},
 number = {1},
 pages = {113--132},
 publisher = {American Economic Association},
 title = {The Economic Costs of Conflict: A Case Study of the Basque Country},
 volume = {93},
 year = {2003}
}

@book{schafer_1997, 
place={Boca Raton}, 
title={Analysis of incomplete multivariate data}, 
publisher={Chapman & Hall/CRC}, 
author={Schafer, J. L.},
 year={1997}
 } 

@article{DS50,
author = {David Donoho},
title = {50 Years of Data Science},
journal = {Journal of Computational and Graphical Statistics},
volume = {26},
number = {4},
pages = {745-766},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/10618600.2017.1384734},

URL = { 
        https://doi.org/10.1080/10618600.2017.1384734
    
},
eprint = { 
        https://doi.org/10.1080/10618600.2017.1384734
    
}
}

@Article{tdv,
    title = {Welcome to the {tidyverse}},
    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
    year = {2019},
    journal = {Journal of Open Source Software},
    volume = {4},
    number = {43},
    pages = {1686},
    doi = {10.21105/joss.01686},
  }

@article{citation_bs,
 ISSN = {00905364},
 URL = {http://www.jstor.org/stable/2958830},
 abstract = {We discuss the following problem: given a random sample X = (X1, X2, ⋯, Xn) from an unknown probability distribution F, estimate the sampling distribution of some prespecified random variable R(X, F), on the basis of the observed data x. (Standard jackknife theory gives an approximate mean and variance in the case R(X, F) = θ(F̂) - θ(F), θ some parameter of interest.) A general method, called the "bootstrap," is introduced, and shown to work satisfactorily on a variety of estimation problems. The jackknife is shown to be a linear approximation method for the bootstrap. The exposition proceeds by a series of examples: variance of the sample median, error rates in a linear discriminant analysis, ratio estimation, estimating regression parameters, etc.},
 author = {B. Efron},
 journal = {The Annals of Statistics},
 number = {1},
 pages = {1--26},
 publisher = {Institute of Mathematical Statistics},
 title = {Bootstrap Methods: Another Look at the Jackknife},
 volume = {7},
 year = {1979}
}
